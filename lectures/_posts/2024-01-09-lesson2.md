---
layout: post
title: Lesson 2 - SDEs and how to condition them
image: /assets/img/lessons/brownian_motion.png
accent_image: 
  background: url('/assets/img/sampling_space.png') center/cover
  overlay: false
accent_color: '#ccc'
theme_color: '#ccc'
description: >
  How to reverse and condition SDEs
invert_sidebar: true
---

# Lesson 2 - SDEs and how to condition them

### Optional reading for this lesson
- [Särkkä & Solin - Applied Stochastic Differential Equations](https://github.com/AaltoML/SDE), chapter 5, 6 and 7
- [Derivation FP Equation for some SDEs (Video)](https://www.youtube.com/watch?v=MmcgT6-lBoY)
- [Ludwig Winkler: Reverse time SDEs (Blogpost)](https://ludwigwinkler.github.io/blog/ReverseTimeAnderson/), same derivation as section 5 in the Anderson paper
- [Ludwig Winkler: Simpler Sketch of Reverse SDE (Blogpost)](https://ludwigwinkler.github.io/blog/SimpleReverseSDE/)
- [Alexandre Thiéry: Reverse diffusions, Score & Tweedie](https://alexxthiery.github.io/posts/reverse_and_tweedie/reverse_and_tweedie.html)


### [Slides](/assets/slides/r255-l2.pdf)

#### Video (soon)

In this lecture we continue with our discussion of SDEs and how to manipulate them. Specifically, we will look how we can describe the evolution of the probability density of an SDE via the Fokker-PLanck Equation, how we can reverse SDEs via Nelsons Duality Formula and how we can condition SDEs via Doob's h-transform.

* toc
{:toc}

## 1. The Fokker-Planck Equation 

In the first lecture we saw that while the solution of an ODE is just a deterministic function, the solution of an SDE is a stochastic process. We can describe this process by the SDE solution, but as a stocastic process it also has properties like a probability distribution and statistics. In this first part, we will therefore look at the Fokker-Planck Equation (FPE), which describes the evolution of the probability density of an SDE and look at the FPE for some common SDEs.

The FPE has [many names](https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation) depending on the field you work in. In physics it is often called the [Smoluchowski equation](https://en.wikipedia.org/wiki/Smoluchowski_equation), in probability theory it is called the [Kolmogorov forward equation](https://en.wikipedia.org/wiki/Kolmogorov_forward_equation) and in statistics it is called the [Fokker-Planck-Kolmogorov equation](https://en.wikipedia.org/wiki/Fokker%E2%80%93Planck_equation#Fokker%E2%80%93Planck%E2%80%93Kolmogorov_equation). In this lecture we will use the term Fokker-Planck Equation (FPE).

> Definition: The Fokker-Planck Equation (FPE) describes the evolution of the probability density of an SDE. For a general SDE of the form $$dX_t = \mu(X_t, t)dt + \sigma(X_t, t)dW_t$$,  it is given by
{:.lead}

$$\frac{\partial}{\partial t} p(x,t) = - \frac{\partial}{\partial x}[\mu(x,t)p(x,t)] + \frac{\partial^2}{\partial x^2}[D(x,t)p(x,t)]$$

>where $$p(x,t)$$ is the probability density of the SDE at time $$t$$ and $$x$$ and $$D(x,t) = \frac{\sigma^2(X_t,t)}{2}$$ is defined as the diffusion coefficient.
{:.lead}

To emphasise that there is a separate probability density for each time step, we will sometimes write the probability density $$p(x,t)$$ as $$p_t(x)$$ instead, where $$x$$ is the value of the SDE at time $$t$$. The FPE describes how this probability density evolves over time.

We will first derive the FPE for the special case of Brownian motion, then derive this general formula here and then look at the FPE for some common SDEs.

For completeness, the FPE for a general SDE of the form $$dX_t = \mu(X_t, t)dt + \sigma(X_t, t)dW_t$$ is given by

$$\partial_t p(x, t) = - \sum_{i=1}^d \partial_{x_i}[\mu_i(xi,t)p(x,t)] + \sum_{i,j=1}^N \partial_{x_i,x_j}[\sigma \sigma_{ij}(x,t)p(x,t)]$$


### 1.1 FPE for Brownian Motion

Let's start with the special case of Brownian motion, a stochastic process we discussed in the first lecture. For generality, let us denote the stochastic process as $$X_t$$, i.e. setting $$X_t = B_t$$ where $$B_t$$ is the Brownian motion.

Our SDE for Brownian motion is therefore (surprise, surprise) given by $$dX_t = dB_t$$.

Let us look at a twice continously differentiable, arbitrary function $$f(X_t)$$ with compact support and apply Ito's lemma to it. We get 

$$
\begin{align}
df(X_t) &= \partial_t f(X_t) dt + \partial_x f(X_t) dX_t + \frac{1}{2} \partial_{xx} f(X_t) (dX_t)^2 \\
        &= \partial_x f(X_t) dB_t + \frac{1}{2} \partial_{xx} f(X_t) dt \\
\mathbb{E}[df(X_t)] &= \mathbb{E}[\partial_x f(X_t) dB_t + \frac{1}{2} \partial_{xx} f(X_t) dt] \hspace{10px} \mid \mathbb{E}[dB_t] = 0\\
                    &= \frac{1}{2} \mathbb{E}[\partial_{xx} f(X_t)] dt \hspace{10px} \mid \text{use dom. convergence theorem}\\
\frac{d}{dt} \mathbb{E}[f(X_t)] &= \frac{1}{2} \mathbb{E}[\partial_{xx} f(X_t)] \hspace{10px} \mid \text{rewrite } \mathbb{E} \text{ and write } \partial_{xx} f(x) = f_{xx}(x)\\
\frac{d}{dt} \int_{-\infty}^{\infty} f(x) p(x,t) dx &= \frac{1}{2} \int_{-\infty}^{\infty} f_{xx}(x) p(x,t) dx \hspace{10px} \mid \text{integrate RHS by parts}\\
                                                    &= \frac{1}{2} [f_{xx}(x)p(x,t)\Big|_{x=-\infty}^{x=\infty} - \int_{-\infty}^{\infty} f_x(x)\frac{\partial p(x,t)}{\partial x}dx] \hspace{10px} \mid \text{compact support: first term = 0}\\
                                                    &= - \frac{1}{2} \int_{-\infty}^{\infty} f_x(x)\frac{\partial p(x,t)}{\partial x}dx \hspace{10px} \mid \text{integrate RHS by parts again}\\
                                                    &= - \frac{1}{2} [f_{x}(x)\frac{\partial p(x,t)}{\partial x}\Big|_{x=-\infty}^{x=\infty} - \int_{-\infty}^{\infty} f(x)\frac{\partial^2 p(x,t)}{\partial x^2}dx] \hspace{10px} \mid \text{compact support: first term = 0}\\
                                                    &= \frac{1}{2} \int_{-\infty}^{\infty} f(x)\frac{\partial^2 p(x,t)}{\partial x^2}dx \hspace{10px} \mid \text{pull derivative inside integral on LHS}\\
\int_{-\infty}^{\infty} f(x) \frac{\partial p(x,t)}{\partial t} dx &= \frac{1}{2} \int_{-\infty}^{\infty} f(x)\frac{\partial^2 p(x,t)}{\partial x^2}dx \hspace{10px} \mid \text{regroup terms}\\
\int_{-\infty}^{\infty} f(x) \frac{\partial p(x,t)}{\partial t} - \frac{1}{2} \frac{\partial^2 p(x,t)}{\partial x^2} f(x) dx &= 0 \hspace{10px} \mid \text{f is arbitrary}\\
\frac{\partial p(x,t)}{\partial t} - \frac{1}{2} \frac{\partial^2 p(x,t)}{\partial x^2} &= 0\\
\end{align}
$$

This is the FPE for Brownian motion and known as the [Diffusion equation](https://en.wikipedia.org/wiki/Diffusion_equation). It looks very similar to the heat equation and can be derived from the general FPE formula by setting $$\mu(x,t) = 0$$ and $$\sigma(x,t) = 1$$.

### 1.2 FPE for General SDEs

Now let's consider how we derive the FPE for a general SDE. The procedure is very similar to the derivation for Brownian motion, but we have to be a bit more careful since now we have a drift term $$\mu(x,t)$$ and a non-constant diffusion term $$\sigma(x,t)$$.



### 1.3 FPE for GBM and OU

We can now use the general FPE formula to derive the FPE for some common SDEs. We will not derive them here from scratch but start from the formula for general SDEs from the last section.

For the zero-centered Ornstien-Uhlenbeck process $$dX_t = -\theta X_t dt + \sigma dB_t$$, we have $$\mu(x,t) = - \theta  x$$ and $$\sigma(x,t) = \sigma$$. Plugging this into the general FPE formula, we get

$$\frac{\partial p(x,t)}{\partial t} = - \theta \frac{\partial}{\partial x} x p(x,t) + \frac{1}{2} \sigma^2 \frac{\partial^2 p(x,t)}{\partial x^2}$$

For the Geometric Brownian Motion $$dX_t = \mu X_t dt + \sigma X_t dB_t$$, we have $$\mu(x,t) = \mu x$$ and $$\sigma(x,t) = \sigma x$$. Plugging this into the general FPE formula, we get

$$\frac{\partial p(x,t)}{\partial t} = - \mu \frac{\partial}{\partial x} x p(x,t) + \frac{1}{2} \sigma^2  \frac{\partial^2 p(x,t) x^2}{\partial x^2}$$

## 2. Time Reversal - Nelson, Anderson and co

In the first lecture we saw that the solution of an SDE is a stochastic process. We can describe this process by the SDE solution, but as a stocastic process it also has properties like a probability distribution and statistics. We now looked at the Fokker-Planck Equation (FPE), which describes the evolution of the probability density of an SDE.

This is all very nice, but the key insight of diffusion models is that we can *reverse* an SDE. The results leading to this conclusion are all decades old (see [Anderson, 1982](https://www.sciencedirect.com/science/article/pii/0304414982900515)), but have only recently been applied in the area of [generative modelling](). In this section we will look at how we can reverse an SDE and what this means for the FPE.

### 2.1 A discrete time "heuristic" sketch

Let's say we have a SDE we want to reverse and know its FPE. We can see the probability densities evolving over time as a joint distribution of the values at all times. If we consider two time points, $$t$$ and $$t+\delta$$, we can factor the joint distribution into conditional probabilities in two ways via the chain rule of probability:

$$p_{t, t+\delta}(x, y) = p_{t+\delta \mid t}(y \mid x) p_t(x) = p_{t \mid t+\delta}(x \mid y) p_{t+\delta}(y)$$

where we denote a random variable at time $$t$$ as $$x$$ and a random variable at time $$t+\delta$$ as $$y$$. 

This is exactly true when $$p$$ is the exact solution of the FPE and therefore the different conditional probabilities are the exact transition densities of our SDE.



However, let us now do a small hack: we discretise time via the Euler-Maruyama method and approximate the transition densities via the Euler-Maruyama transition densities. As a reminder, an Euler-Maruyama discretisation step for our typical SDE $$dX_t = \mu(t, X_t) dt + \sigma(t, X_t) dW_t$$ after partitioning it into $$n$$ discrete intervals looks like

$$X_{n+1} = X_{n} + \mu(X_{n}, n) \delta t + \sigma(X_{n}, n) \delta W_{n} \label{eq1}$$

If we assume this discretisation, the transition density equality we wrote down above is not valid anymore except for the limit $$\delta \rightarrow 0$$. In this approximation, the forward transition density is aGaussian that depends on the drift and diffusion term in the following way \ref{eq1}:

$$
\begin{align}
p_{t+\delta \mid t}(y \mid x) &= \mathcal{N}(y \mid x + f^+(x) \delta, \delta \sigma^2(x))
\end{align}
$$

where we denote the drift term at time $$t$$ as $$f^+(x) = \mu(x, t)$$ and ignore the time dependency of the drift and diffusion terms for simplicity.

We now want to get an expression for the reverse transition density $$p_{t \mid t+\delta}(x \mid y)$$. Rearranging the chain rule decomposition above, we get

$$p_{t \mid t+\delta}(x \mid y) = p_{t+\delta \mid t}(y \mid x) \frac{p_{t}(x)}{p_{t+\delta}(y)}$$

We can now use [Taylor's theorem](https://en.wikipedia.org/wiki/Taylor%27s_theorem) to expand the marginal densities $$p_t$$ around $$y$$:

$$
\begin{align}
p_{t}(x) &= p_{t}(y) + (x-y) \frac{\partial p_{t}(x)}{\partial x} \Big|_{x=y}+ \mathcal{O}(\delta^2) \hspace{10px} \mid \text{exponentiate} \\
&= p_{t}(y) \exp((x-y) \nabla_y \ln p_t(y) + \mathcal{O}(\delta^2)) \\
\end{align}
$$










### 2.2 Time Reversal in score-based models

## 3. Score-based modelling via SDEs

[Score matching](https://jmlr.org/papers/volume6/hyvarinen05a/hyvarinen05a.pdf)

[Thread about Hyvarinen papers](https://twitter.com/volokuleshov/status/1739456111827390592)


## 4. Probability flow ODE

## 5. Flow Matching

## 6. Conditioning - Doob's h-transform

### 6.1 Example for pinned Brownian motion

## 7. Conditioning in score-based models

## Credits

Much of the logic in the lecture is based on the Oksendal as well as the Särkkä & Solin book. Title image from [Wikipedia]().