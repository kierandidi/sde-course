---
layout: post
title: Lesson 1 - A very fast paced introduction to the foundations
image: /assets/img/lessons/measure.png
accent_image: 
  background: url('/assets/img/sampling_space.png') center/cover
  overlay: false
accent_color: '#ccc'
theme_color: '#ccc'
description: >
  How to view probability from a measure theoretic perspective.
invert_sidebar: true
---

# Lesson 1 - A very fast paced introduction to the foundations

### Required reading for this lesson

### Optional reading for this lesson

### [Slides](/assets/slides/r255-l1.pdf)

#### Video (soon)


In this lecture we give a very fast paced introduction to a perspective on probability some of you might have encountered, some of you might have not: measure theory.


*[SERP]: Search Engine Results Page

## 1. Measure Theory and Probability


## 2. Stochastic Processes and Martingales

Now let's talk about stochastic processes, where we thing about dynamic random variables that evolve over time. Let T be a set of times.

> Definition: A **stochastic process** $$\{X_t\}_{t \in T}$$ is a collection of random variables $$X_t$$ defined on a common probability space $$(\Omega, \mathcal{F}, \mathbb{P})$$.
{:.lead}

We can think of a stochastic process as a function $$X: T \times \Omega \rightarrow \mathbb{R}$$ that maps a time $$t$$ and a sample point $$\omega$$ to a real number $$X_t(\omega)$$.

> Definition: A **filtration** $$\{F_t\}$$ is a family of sub-sigma algebras of $$\mathcal{F}$$ such that $$F_s \subseteq F_t$$ for $$0 \leq s \leq t$$.
{:.lead}

We see that the sub-sigma algebras $$F_t$$ are nested, i.e. $$F_0 \subseteq F_1 \subseteq F_2 \subseteq ...$$. They also get thinner over time, meaning that the information we have about the process increases over time. This is a natural property of stochastic processes, since we can only observe the process over time and therefore only get more information about it over time.

> Definition: A stochastic process $$\{X_t\}_{t \in T}$$ is **adapted** to a filtration $$\{F_t\}$$ if $$X_t$$ is $$F_t$$-measurable for all $$t \in T$$.
{:.lead}

This means that the random variable $$X_t$$ is measurable with respect to the sigma algebra $$F_t$$, i.e. we can observe the value of $$X_t$$ at time $$t$$ by observing the sigma algebra $$F_t$$. Adapted processes are also called *non-anticipating* processes, since we cannot anticipate the value of $$X_t$$ at time $$t$$ by observing the sigma algebra $$F_s$$ for $$s > t$$. In other words, we cannot see into the future; $$X_t$$ is only know at time $$t$$. 

An additional key idea contained in this is that the sigma algebra $$F_t$$ contains all the information we have about the process up to time $$t$$, i.e. it describes not only the value of $$X_t$$ at time $$t$$, but also everything before it.

<!-- INSERT PICTURE WITH ARROWS STATIC AND DYNAMIC RVs see notes -->

From these definitions, we can now define the concept of a martingale. Intuitively, a martingale is a stochastic process that has constant expected value over time. Let's see how we can define this formally.

> Definition: A stochastic process $$\{X_t\}_{t \in T}$$ is a **martingale** with respect to a filtration $$\{F_t\}$$ if:  
1. $$X_t$$ is integrable for all $$t \in T$$
2. $$X_t$$ is adapted to $$F_t$$ for all $$t \in T$$
3. $$\mathbb{E}[X_t \mid F_s] = X_s$$ for all $$0 \leq s \leq t$$.
{:.lead}

The last statement is equivalent to $$\mathbb{E}[X_t - X_s \mid F_s] = 0$$ since $$\mathbb{E}[X_s \mid F_t] = X_s$$ and we can therefore pull $$-X_s$$ into the expectation. This means that the expected value of the change in $$X_t$$ from time $$s$$ to time $$t$$ is zero. This means that the expected value of $$X_t$$ at time $$t$$ is equal to the expected value of $$X_s$$ at time $$s$$, i.e. the expected value of $$X_t$$ is constant over time. This is the key property of a martingale. 


## 3. Brownian Motion

Before we finally come to stochastic differential equations, let's talk about Brownian motion. Brownian motion is a stochastic process that is a martingale and is central to Ito integration theory which we will discuss a lot about later, so it is worth dwelling on it a bit. 

> Definition: A stochastic process $$B_t$$ is a **Brownian motion** if:
1. $$B_0 = 0$$ (process starts at $$0$$)
2. $$B_t$$ is almost surely continuous
3. $$B_t$$ has independent increments ($$B_t - B_s$$ is independent of $$B_s$$)
4. $$B_t - B_s \sim \mathcal{N}(0, t-s)$$ (for $$0 \leq s \leq t$$)
{:.lead}

From this definition, we can derive some properties of Brownian motion:

1. $$\mathbb{E}[B_t] = 0$$ (since $$B_t$$ follows a centered normal distribution)
2. $$\mathbb{E}[B_t^2] = t = var(B_t)$$. This is a key property of Brownian motion and is called the *quadratic variation* of Brownian motion. It is the reason why we cannot ignore the second term in the Taylor expansion of Ito's lemma as we will later see. We can show this by noting that $$var(B_t) = \mathbb{E}[B_t^2] - \mathbb{E}[B_t]^2 = \mathbb{E}[B_t^2]$$ since $$\mathbb{E}[B_t] = 0$$.
3. $$B_t$$ is a martingale. The first two martingale properties are easy to show: $$B_t$$ is integrable for all $$t$$ since it follows a normal distribution and it is $$F_t$$-adapted. For the third martingale property, we make use of a common trick when working with Brownian motion: we try to an increment appear in an expectation and then use that this is 0 by definition of Brownian motion. We can write:

$$\mathbb{E}[B_t \mid B_s] = \mathbb{E}[B_t - B_s + B_s \mid B_s] = \mathbb{E}[B_t - B_s] + B_s = B_s$$

## 4. ODEs

Now that we have a measure theoretic perspective on probability and some feeling for what stochastic processes are, we can start to think about how to define stochastic differential equations.

To do this, let's first remember what an ordinary differential equation is. An ordinary differential equation is a differential equation that contains one or more functions of one independent variable and the derivatives of those functions. The term ordinary is used in contrast with the term partial differential equation which may be with respect to more than one independent variable. An example ODE is the following:

$$\frac{d x}{d t} = -\alpha x$$

This is a first order ODE, because it contains the first derivative of $$x$$. It is also a linear ODE, because it is linear in $$x$$. It is also an time-invariant ODE, because it does not depend on $$t$$.

In general, we often write *linear differential equations* like this:

$$\frac{d x}{d t} = F(t) x(t) + L(t) w(t)$$

where $$F(t)$$ is a function of time, $$x(t)$$ is the state of the system at time $$t$$, $$L(t)$$ is a function of time and $$w(t)$$ is some forcing or driving function; in applications, this coud for example be an input to a system.

A useful special case of this are *linear time-invariant differential equations*:

$$\frac{d x}{d t} = F x(t) + L w(t)$$

where $$F$$ and $$L$$ are constant. We can solve such equations via methods like *separation of variables* or, for the case of *inhomgeneous* equations, via the *integrating factor* method.

For general linear differential equations, we can solve them via methods like Fourier or Laplace transforms or via numerical methods. Linear differential equations are useful to consider since they arise in many equations and can be solved analytically. They will also be useful for us to consider when we think about stochastic differential equations.

## 5. SDEs

A pragmatic way to think about stochastic differential equations is to think about them as ODEs with some noise added. For example, let's think about a car in 2 dimensions that is governed by the following ODE resulting from Newton's second law:

$$
\begin{aligned}
\textbf{f}(t) &= m \textbf{a}(t) \\
              &= m \frac{d^2 \textbf{x}(t)}{d t^2}
\end{aligned}
$$

where $$\textbf{f}(t)$$ is the force acting on the car, $$m$$ is the mass of the car, $$\textbf{a}(t)$$ is the acceleration of the car and $$\textbf{x}(t)$$ is the position of the car. 

Let's say that our acceleration is now not precisely known/we have a measurement error in our acceleration. We can model this by adding some noise to our acceleration and descrie it by a random white-noise process $$\textbf{w}(t) = (w_1(t), w_2(t))$$:

$$
\begin{aligned}
\frac{d^2 x_1(t)}{d t^2} &= w_1(t);   
\frac{d^2 x_1(t)}{d t^2} &= w_2(t)
\end{aligned}
$$

Now if we define $$x_3 = \frac{d x_1(t)}{d t}$$ and $$x_4 = \frac{d x_2(t)}{d t}$$ we can write this as a system of first order ODEs in our old familiar form:

$$
\begin{aligned}
\frac{d \textbf{x}(t)}{d t} \left(\begin{array}{c}
                 x_1 \\
                 x_2 \\
                 x_3 \\
                 x_4
               \end{array}\right) &= \left(\begin{array}{ccc}
                 0  & 0 & 1 & 0 \\
                 0  & 0 & 0 & 1 \\
                 0  & 0 & 0 & 0 \\
                 0  & 0 & 0 & 0
               \end{array}\right) \left(\begin{array}{c}
                 x_1 \\
                 x_2 \\
                 x_3 \\
                 x_4
               \end{array}\right) + \left(\begin{array}{cc}
                 0  & 0 \\
                 0  & 0 \\
                 1  & 0 \\
                 0  & 1 
                \end{array}\right) \left(\begin{array}{c}
                w_1 \\
                w_2 \\ 
                \end{array}\right)
\end{aligned}
$$

where the first matrix is $$F$$ and the second matrix is $$L$$. This is a linear time-invariant differential equation where the forcing function is not deterministic but a stochastic process: a stochastic differential equation.

Let's try to solve such an equation heuristically with initial condition $$\textbf{x}(t_0) \sim \mathcal{N}(\textbf{m}_0, \textbf{P}_0)$$. If we pretend that $$\textbf{w}(t)$$ is deterministic and continuous (which it is not), we can solve this equation like we would solve any other ODE. We can write the solution via the method of integrating factor as:

$$
\begin{aligned}
\frac{d \textbf{x}}{d t} &= \textbf{F} \textbf{x}(t) + \textbf{L} \textbf{w}(t) \\
\frac{d \textbf{x}}{d t} - \textbf{F} \textbf{x}(t) &= \textbf{L} \textbf{w}(t) \\
exp(-\textbf{F} t) \frac{d \textbf{x}}{d t} - exp(-\textbf{F} t) \textbf{F} \textbf{x}(t) &= exp(-\textbf{F} t) \textbf{L} \textbf{w}(t) \\
\frac{d}{d t} exp(-\textbf{F} t) \textbf{x}(t) &= exp(-\textbf{F} t) \textbf{L} \textbf{w}(t) \\
exp(-\textbf{F} t) \textbf{x}(t) - exp(-\textbf{F} t_0) \textbf{x}(t_0) &= \int_{t_0}^t exp(-\textbf{F} s) \textbf{L} \textbf{w}(s) ds \\
\textbf{x}(t) &= exp(\textbf{F}(t-t_0)) \textbf{x}(t_0) + \int_{t_0}^t exp(\textbf{F}(t-s)) \textbf{L} \textbf{w}(s) ds
\end{aligned}
$$

where $$t_0$$ is the initial time and $$exp()$$ is the matrix exponential. Let us continue to pretend that $$\textbf{w}(t)$$ is deterministic and continuous. Then taking expectation on both side yields:

$$
\begin{aligned}
\mathbb{E}[\textbf{x}(t)] &= \mathbb{E}[exp(\textbf{F}(t-t_0)) \textbf{x}(t_0)] + \mathbb{E}[\int_{t_0}^t exp(\textbf{F}(t-s)) \textbf{L}\textbf{w}(s) ds] \\
                          &= \mathbb{E}[exp(\textbf{F}(t-t_0)) \textbf{x}(t_0)] \\
                          &= exp(\textbf{F}(t-t_0)) \textbf{m}_0
\end{aligned}
$$

where we used in the first step that $$\mathbb{E}[\textbf{w}(s)] = 0$$ since this is one of the properties of the white noise process and in the second step that $$\mathbb{E}[\textbf{x}(t_0)] = \textbf{m}_0$$ since this was our initial condition.

We can also get a covariance equation by recalling the Dirac delta correlation proeprty of the white noise process $$\textbf{P}(t,s) = \mathbb{E}[\textbf{w}(t) \textbf{w}^T(s)] = \delta(t-s) \textbf{Q}$$ with $$\textbf{Q}$$ being the spectral density of the white noise process. Then we can write (for $$t_0 = 0$$ and $$m(t) = \mathbb{E}[\textbf{x}(t)]$$):

$$
\begin{aligned}
\textbf{P}(t, t_0) &= \mathbb{E}[(\textbf{x}(t) - \mathbb{E}[\textbf{x}(t)])(\textbf{x}(t) - \mathbb{E}[\textbf{x}(t)])^T] \\
                   &= \mathbb{E}[(\textbf{x}(t) - \textbf{m}(t))(\textbf{x}(t) - \textbf{m}(t))^T] \\
              &= \mathbb{E}[\textbf{x}(t)\textbf{x}(t)^T] - \mathbb{E}[\textbf{x}(t)\textbf{m}(t)^T] - \mathbb{E}[\textbf{m}(t)\textbf{x}(t)^T] + \mathbb{E}[\textbf{m}(t)\textbf{m}(t)^T]\\
              &= exp(\textbf{F}(t)) \textbf{P}_0 exp(\textbf{F}(t))^T\\
              &= \\
              &= exp(\textbf{F}(t)) \textbf{P}_0 exp(\textbf{F}(t))^T + \int_0^t exp(\textbf{F}(t-s)) \textbf{L} \textbf{Q} \textbf{L}^T exp(\textbf{F}(t-s))^T ds
\end{aligned}
$$

where in step 3 we used $$\mathbb{E}[\textbf{x}(t)] = exp(\textbf{F}(t-t_0))\textbf{m}_0$$ and $$\textbf{m}_0\textbf{m}_0^T = \textbf{P}_0$$.

We can now get the the differential equations for the mean and covariance by taking the derivative of the mean and covariance equations with respect to $$t$$ (where we denote $$m(t) = \mathbb{E}[\textbf{x}(t)]$$ and $$\textbf{P}(t) = \mathbb{E}[(\textbf{x}(t) - \mathbb{E}[\textbf{x}(t)])(\textbf{x}(t) - \mathbb{E}[\textbf{x}(t)])^T]$$):

$$
\begin{aligned}
\frac{d \mathbb{E}[\textbf{x}(t)]}{d t} &= \\
                                        &= \textbf{F} \mathbb{E}[\textbf{x}(t)] \\
\frac{d \textbf{P}(t)}{d t} &= \\
                            &= \textbf{F} \textbf{P}(t) + \textbf{P}(t) \textbf{F}^T + \textbf{L} \textbf{Q} \textbf{L}^T
\end{aligned}
$$



## 6s. Ito Integral

This seems easy enough, we can just solve this like we would solve any other ODE, right? Well, not quite. The problem is that the noise process $$\textbf{w}(t)$$ is not a regular function, but a random process. This means that we cannot just integrate it like we would integrate a regular function. We need a new way to integrate random processes. This is where the Ito integral comes in.

To see the problem, let's consider 

## 7. Ito's Lemma

So far we defined the stochastic integral in the Ito formulation. Now we want to see how we can solve these integrals in order to make progress with a proper treatment of our SDEs beyond the heuristic treatment we did before. To do this, we will use *Ito's lemma*, which is a generalization of the chain rule for stochastic processes. It basically is a Taylor expansiona adapted to the stochastic world and a key tool in stochastic calculus.

Let's sketch how we get to Ito's lemma by considering a Taylor series for a function $$f(x)$$ around $$0$$ in ordinary calculus:

$$d f(x) = f'(x) dx + \frac{1}{2} f''(x)(dx)^2$$

Example: $$f(x) = x^2$$

$$d f(x) = 2 x dx + \frac{1}{2} f''(x) (dx)^2$$

However, for ordinary functions, $$(dx)^2$$ will be very small since our partitions $$dx$$ are very small to begin with. The corresponding change in function value that this term induces will be very small since our function is continuous and differentiable.

Therefore, we can ignore the second term and write:

$$d f(x) = f'(x) dx = 2 x dx$$

How does this look like in stochastic calculus? We again consider the change in $$f(x)$$, but now we consider $$x$$ to be a stochastic process and therefore denote it is $$X_t$$. We can write the change in $$f(X_t)$$ as:

$$df(X_t) = $$\frac{\partial f(X_t)}{\partial X_t} dX_t + \frac{1}{2} \frac{\partial^2 f(X_t)}{\partial X_t^2} (dX_t)^2$$

where $$dX_t$$ is the change in $$X_t$$ and $$(dX_t)^2$$ is the quadratic variation of $$X_t$$. Now in a stochastic process like Brownian motion, the quadratic variation in the limit of infinitely small partitions is not converging to zero, but to the time step $$dt$$ (we have described this before in the properties of Brownian motion). Therefore, we cannot ignore the second term in the Taylor expansion and have to keep it. This is the key insight of Ito's lemma.

We can use Ito's lemma for all Ito processes.

> Definition: An **Ito process** is an adapted stochastic process $$X_t$$ that can be expressed as the sum of an integral with respect to time and an integral with respect to a Brownian motion $$B_t$$:
$$dX_t = \mu(t, X_t) dt + \sigma(t, X_t) dB_t$$
{:.lead}

Here $$\mu(t, X_t)$$ is the drift term and $$\sigma(t, X_t)$$ is the diffusion term. We can think of the drift term as the deterministic part of the process and the diffusion term as the stochastic part of the process.

Now we can formulate what Ito's lemma is for these Ito processes:

> **Ito's lemma**: Let $$X_t$$ be an Ito process and $$f(t, X_t)$$ be a function of $$t$$ and $$X_t$$ that is twice continuously differentiable with respect to $$t$$ and $$X_t$$. Then $$f(t, X_t)$$ is also an Ito process, can be denoted Y_t and we can write:

$$ dY_t = df(t, X_t) = \frac{\partial f(t, X_t)}{\partial t} dt + \frac{\partial f(t, X_t)}{\partial X_t} dX_t + \frac{1}{2} \frac{\partial^2 f(t, X_t)}{\partial X_t^2} (dX_t)^2$$
{:.lead}

where we can use $$df(t, X_t) = f_t dt + f_X dX_t + \frac{1}{2}f_{XX}(dX_t)^2$$ as a simpler notation for the first equation. This is the stochastic version of the Taylor expansion we saw before. We can also write this in integral form:

$$Y_t = f(t, X_t) = f(t_0, X_{t_0}) + \int_{t_0}^t f_t(s, X_s) ds + \int_{t_0}^t f_X(s, X_s) dX_s + \frac{1}{2} \int_{t_0}^t f_{XX}(s, X_s) (dX_s)^2$$

where the first term is the initial value of $$f(t, X_t)$$, the second term is the deterministic part of the process, the third term is the stochastic part of the process and the fourth term is the correction term that arises from the quadratic variation of the stochastic process.

Finally, another version of Ito's lemma in its differential form that you will often see is the following:

$$dY_t = df(t, X_t) = (\frac{\partial f(t, X_t)}{\partial x} \mu(t, X_t) + \frac{\partial f(t, X_t)}{\partial t} + \frac{1}{2} \frac{\partial^2 f(t, X_t)}{\partial x^2} \sigma(t, X_t)^2) dt + \frac{\partial f(t, X_t)}{\partial x} \sigma(t, X_t) dB_t$$

Here we used the original differential form, substituted $$dX_t$$ with the Ito process, $$(dX_t)^2$$ with the quadratic variation of the Ito process $$\sigma(t, X_t)^2$$ and then simplified the resulting expression by grouping $$dt$$ and $$dB_t$$ terms.


## 8. Solving linear SDEs
