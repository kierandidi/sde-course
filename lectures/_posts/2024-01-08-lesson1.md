---
layout: post
title: Lesson 1 - A very fast paced introduction to the foundations
image: /assets/img/lessons/measure.png
accent_image: 
  background: url('/assets/img/sampling_space.png') center/cover
  overlay: false
accent_color: '#ccc'
theme_color: '#ccc'
description: >
  How to view probability from a measure theoretic perspective.
invert_sidebar: true
---

# Lesson 1 - A very fast paced introduction to the foundations

### Required reading for this lesson

### Optional reading for this lesson

### [Slides](/assets/slides/r255-l1.pdf)

#### Video (soon)


In this lecture we give a very fast paced introduction to a perspective on probability some of you might have encountered, some of you might have not: measure theory.


*[SERP]: Search Engine Results Page

## 1. Measure Theory


## 2. ODEs

Now that we have a measure theoretic perspective on probability, we can start to think about how to define stochastic differential equations.

To do this, let's first remember what an ordinary differential equation is. An ordinary differential equation is a differential equation that contains one or more functions of one independent variable and the derivatives of those functions. The term ordinary is used in contrast with the term partial differential equation which may be with respect to more than one independent variable. An example ODE is the following:

$$\frac{d x}{d t} = -\alpha x$$

This is a first order ODE, because it contains the first derivative of $$x$$. It is also a linear ODE, because it is linear in $$x$$. It is also an time-invariant ODE, because it does not depend on $$t$$.

In general, we often write *linear differential equations* like this:

$$\frac{d x}{d t} = F(t) x(t) + L(t) w(t)$$

where $$F(t)$$ is a function of time, $$x(t)$$ is the state of the system at time $$t$$, $$L(t)$$ is a function of time and $$w(t)$$ is some forcing or driving function; in applications, this coud for example be an input to a system.

A useful special case of this are *linear time-invariant differential equations*:

$$\frac{d x}{d t} = F x(t) + L w(t)$$

where $$F$$ and $$L$$ are constant. We can solve such equations via methods like *separation of variables* or, for the case of *inhomgeneous* equations, via the *integrating factor* method.

For general linear differential equations, we can solve them via methods like Fourier or Laplace transforms or via numerical methods. Linear differential equations are useful to consider since they arise in many equations and can be solved analytically. They will also be useful for us to consider when we think about stochastic differential equations.

## 3. SDEs

A pragmatic way to think about stochastic differential equations is to think about them as ODEs with some noise added. For example, let's think about a car in 2 dimensions that is governed by the following ODE resulting from Newton's second law:

$$
\begin{aligned}
\textbf{f}(t) &= m \textbf{a}(t) \\
              &= m \frac{d^2 \textbf{x}(t)}{d t^2}
\end{aligned}
$$

where $$\textbf{f}(t)$$ is the force acting on the car, $$m$$ is the mass of the car, $$\textbf{a}(t)$$ is the acceleration of the car and $$\textbf{x}(t)$$ is the position of the car. 

Let's say that our acceleration is now not precisely known/we have a measurement error in our acceleration. We can model this by adding some noise to our acceleration and descrie it by a random white-noise process $$\textbf{w}(t) = (w_1(t), w_2(t))$$:

$$
\begin{aligned}
\frac{d^2 x_1(t)}{d t^2} &= w_1(t);   
\frac{d^2 x_1(t)}{d t^2} &= w_2(t)
\end{aligned}
$$

Now if we define $$x_3 = \frac{d x_1(t)}{d t}$$ and $$x_4 = \frac{d x_2(t)}{d t}$$ we can write this as a system of first order ODEs in our old familiar form:

$$
\begin{aligned}
\frac{d \textbf{x}(t)}{d t} \left(\begin{array}{c}
                 x_1 \\
                 x_2 \\
                 x_3 \\
                 x_4
               \end{array}\right) &= \left(\begin{array}{ccc}
                 0  & 0 & 1 & 0 \\
                 0  & 0 & 0 & 1 \\
                 0  & 0 & 0 & 0 \\
                 0  & 0 & 0 & 0
               \end{array}\right) \left(\begin{array}{c}
                 x_1 \\
                 x_2 \\
                 x_3 \\
                 x_4
               \end{array}\right) + \left(\begin{array}{cc}
                 0  & 0 \\
                 0  & 0 \\
                 1  & 0 \\
                 0  & 1 
                \end{array}\right) \left(\begin{array}{c}
                w_1 \\
                w_2 \\ 
                \end{array}\right)
\end{aligned}
$$

where the first matrix is $$F$$ and the second matrix is $$L$$. This is a linear time-invariant differential equation where the forcing function is not deterministic but a stochastic process: a stochastic differential equation.

Let's try to solve such an equation heuristically with initial condition $$\textbf{x}(t_0) \sim \mathcal{N}(\textbf{m}_0, \textbf{P}_0)$$. If we pretend that $$\textbf{w}(t)$$ is deterministic and continuous (which it is not), we can solve this equation like we would solve any other ODE. We can write the solution via the method of integrating factor as:

$$
\begin{aligned}
\frac{d \textbf{x}}{d t} &= \textbf{F} \textbf{x}(t) + \textbf{L} \textbf{w}(t) \\
\frac{d \textbf{x}}{d t} - \textbf{F} \textbf{x}(t) &= \textbf{L} \textbf{w}(t) \\
exp(-\textbf{F} t) \frac{d \textbf{x}}{d t} - exp(-\textbf{F} t) \textbf{F} \textbf{x}(t) &= exp(-\textbf{F} t) \textbf{L} \textbf{w}(t) \\
\frac{d}{d t} exp(-\textbf{F} t) \textbf{x}(t) &= exp(-\textbf{F} t) \textbf{L} \textbf{w}(t) \\
exp(-\textbf{F} t) \textbf{x}(t) - exp(-\textbf{F} t_0) \textbf{x}(t_0) &= \int_{t_0}^t exp(-\textbf{F} s) \textbf{L} \textbf{w}(s) ds \\
\textbf{x}(t) &= exp(\textbf{F}(t-t_0)) \textbf{x}(t_0) + \int_{t_0}^t exp(\textbf{F}(t-s)) \textbf{L} \textbf{w}(s) ds
\end{aligned}
$$

where $$t_0$$ is the initial time and $$exp()$$ is the matrix exponential. Let us continue to pretend that $$\textbf{w}(t)$$ is deterministic and continuous. Then taking expectation on both side yields:

$$
\begin{aligned}
\mathbb{E}[\textbf{x}(t)] &= \mathbb{E}[exp(\textbf{F}(t-t_0)) \textbf{x}(t_0)] + \mathbb{E}[\int_{t_0}^t exp(\textbf{F}(t-s)) \textbf{L}\textbf{w}(s) ds] \\
                          &= \mathbb{E}[exp(\textbf{F}(t-t_0)) \textbf{x}(t_0)] \\
                          &= exp(\textbf{F}(t-t_0)) \textbf{m}_0
\end{aligned}
$$

where we used in the first step that $$\mathbb{E}[\textbf{w}(s)] = 0$$ since this is one of the properties of the white noise process and in the second step that $$\mathbb{E}[\textbf{x}(t_0)] = \textbf{m}_0$$ since this was our initial condition.

We can also get a covariance equation by recalling the Dirac delta correlation proeprty of the white noise process $$\textbf{P}(t,s) = \mathbb{E}[\textbf{w}(t) \textbf{w}^T(s)] = \delta(t-s) \textbf{Q}$$ with $$\textbf{Q}$$ being the spectral density of the white noise process. Then we can write (for $$t_0 = 0$$ and $$m(t) = \mathbb{E}[\textbf{x}(t)]$$):

$$
\begin{aligned}
\textbf{P}(t, t_0) &= \mathbb{E}[(\textbf{x}(t) - \mathbb{E}[\textbf{x}(t)])(\textbf{x}(t) - \mathbb{E}[\textbf{x}(t)])^T] \\
                   &= \mathbb{E}[(\textbf{x}(t) - \textbf{m}(t))(\textbf{x}(t) - \textbf{m}(t))^T] \\
              &= \mathbb{E}[\textbf{x}(t)\textbf{x}(t)^T] - \mathbb{E}[\textbf{x}(t)\textbf{m}(t)^T] - \mathbb{E}[\textbf{m}(t)\textbf{x}(t)^T] + \mathbb{E}[\textbf{m}(t)\textbf{m}(t)^T]\\
              &= exp(\textbf{F}(t)) \textbf{P}_0 exp(\textbf{F}(t))^T\\
              &= \\
              &= exp(\textbf{F}(t)) \textbf{P}_0 exp(\textbf{F}(t))^T + \int_0^t exp(\textbf{F}(t-s)) \textbf{L} \textbf{Q} \textbf{L}^T exp(\textbf{F}(t-s))^T ds
\end{aligned}
$$

where in step 3 we used $$\mathbb{E}[\textbf{x}(t)] = exp(\textbf{F}(t-t_0))\textbf{m}_0$$ and $$\textbf{m}_0\textbf{m}_0^T = \textbf{P}_0$$.

We can now get the the differential equations for the mean and covariance by taking the derivative of the mean and covariance equations with respect to $$t$$ (where we denote $$m(t) = \mathbb{E}[\textbf{x}(t)]$$ and $$\textbf{P}(t) = \mathbb{E}[(\textbf{x}(t) - \mathbb{E}[\textbf{x}(t)])(\textbf{x}(t) - \mathbb{E}[\textbf{x}(t)])^T]$$):

$$
\begin{aligned}
\frac{d \mathbb{E}[\textbf{x}(t)]}{d t} &= \\
                                        &= \textbf{F} \mathbb{E}[\textbf{x}(t)] \\
\frac{d \textbf{P}(t)}{d t} &= \\
                            &= \textbf{F} \textbf{P}(t) + \textbf{P}(t) \textbf{F}^T + \textbf{L} \textbf{Q} \textbf{L}^T
\end{aligned}
$$



## 4. Ito Integral

This seems easy enough, we can just solve this like we would solve any other ODE, right? Well, not quite. The problem is that the noise process $$\textbf{w}(t)$$ is not a regular function, but a random process. This means that we cannot just integrate it like we would integrate a regular function. We need a new way to integrate random processes. This is where the Ito integral comes in.

To see the problem, let's consider 

## 5. Ito's Lemma

## 6. Solving linear SDEs
